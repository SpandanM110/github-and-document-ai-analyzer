# AI Repository & Document Analyzer

A powerful Next.js application that analyzes GitHub repositories and documents using AI to provide comprehensive insights, visualizations, and summaries.

## What It Does

- **GitHub Repository Analysis**: Analyze any public GitHub repository to get detailed insights about its purpose, technologies, contributors, and potential use cases
- **Document Analysis**: Upload PDF, Markdown, or text files to extract content and generate AI-powered analysis
- **Smart Visualizations**: Interactive charts showing repository stats, language distribution, and contributor data
- **AI-Powered Insights**: Uses Google Gemini AI to provide detailed summaries, feature lists, technology stacks, and real-world use cases

## Technologies & Tools

### Frontend & Framework
- **Next.js 15** - React framework with App Router
- **React 19** - UI library
- **TypeScript** - Type-safe JavaScript
- **Tailwind CSS** - Utility-first CSS framework
- **shadcn/ui** - Modern UI component library

### AI & APIs
- **Google Gemini AI** - Text analysis and content generation
- **Jina AI** - Professional PDF text extraction
- **GitHub API** - Repository data fetching
- **Gemini Vision** - AI-powered PDF reading

### Data Visualization
- **Recharts** - Interactive charts and graphs
- **Lucide React** - Beautiful icons

### Document Processing
- **Cheerio** - HTML parsing for web scraping
- **PDF Processing** - Multiple extraction methods for reliable text extraction

### Deployment & Build
- **Vercel** - Serverless deployment platform
- **Webpack** - Module bundler with custom configurations

## Main Approach

### 1. **Multi-Source Analysis**
The application takes two main input types:
- **GitHub Repository URLs** - Fetches comprehensive data via GitHub API
- **Document Uploads** - Processes PDF, Markdown, and text files

### 2. **Intelligent Data Extraction**
- **Repository Data**: Stars, forks, languages, contributors, README content, topics
- **Document Content**: Smart text extraction with validation to filter out corrupted data
- **Content Validation**: Ensures extracted text is meaningful and readable

### 3. **AI-Powered Analysis Pipeline**
\`\`\`
Input ‚Üí Data Extraction ‚Üí Content Validation ‚Üí AI Analysis ‚Üí Structured Output
\`\`\`

- Uses Google Gemini AI with carefully crafted prompts
- Analyzes actual content rather than providing generic responses
- Generates structured insights including summaries, features, technologies, and use cases

### 4. **Smart PDF Processing**
Multiple extraction methods with fallbacks:
1. **Jina AI** - Professional PDF parsing service
2. **Gemini Vision** - AI reads PDFs like a human
3. **Content Quality Validation** - Filters out garbage/corrupted data

### 5. **Interactive Visualizations**
- Repository statistics (stars vs forks)
- Programming language distribution
- Top contributors analysis
- Responsive charts that work on all devices

## üîß Key Features

- **Dual Analysis Modes**: GitHub repositories and document uploads
- **Smart Content Validation**: Automatically detects and rejects corrupted/meaningless content
- **Professional PDF Processing**: Uses enterprise-grade APIs for reliable text extraction
- **Comprehensive AI Analysis**: Detailed insights about purpose, technologies, and use cases
- **Interactive Charts**: Visual representation of repository metrics and language usage
- **Responsive Design**: Works seamlessly on desktop and mobile devices
- **Error Handling**: Graceful fallbacks and helpful error messages

## Getting Started

1. **Clone the repository**
\`\`\`bash
git clone <repository-url>
cd ai-repository-analyzer
\`\`\`

2. **Install dependencies**
\`\`\`bash
npm install
\`\`\`

3. **Set up environment variables**
\`\`\`bash
# Required
GEMINI_API_KEY=your_gemini_api_key_here

# Optional (for enhanced features)
GITHUB_TOKEN=your_github_token_here
JINA_API_KEY=your_jina_api_key_here
\`\`\`

4. **Run the development server**
\`\`\`bash
npm run dev
\`\`\`

5. **Open [http://localhost:3000](http://localhost:3000)**

## Environment Variables

- `GEMINI_API_KEY` - **Required** for AI analysis
- `GITHUB_TOKEN` - Optional, increases GitHub API rate limits
- `JINA_API_KEY` - Optional, enables professional PDF parsing

## Use Cases

- **Developer Research**: Quickly understand new repositories and their technologies
- **Document Analysis**: Extract insights from technical documentation, research papers, and reports
- **Project Planning**: Analyze similar projects to understand technology choices and approaches
- **Educational**: Learn about different programming languages and frameworks used in real projects
- **Content Review**: Quickly summarize and analyze large documents

## Architecture

The application follows a modern serverless architecture:
- **Frontend**: React components with TypeScript
- **API Routes**: Next.js API routes for server-side processing
- **AI Integration**: Direct API calls to Gemini and Jina AI services
- **Data Processing**: Client-side and server-side data transformation
- **Deployment**: Optimized for Vercel's serverless platform

---

Built with ‚ù§Ô∏è using Next.js, AI APIs, and modern web technologies.



## Main Code for PDF and JINA AI
```js
import { NextRequest, NextResponse } from 'next/server'

const GEMINI_API_KEY = process.env.GEMINI_API_KEY
const JINA_API_KEY = process.env.JINA_API_KEY

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData()
    const file = formData.get('file') as File
    
    if (!file) {
      return NextResponse.json({ error: 'No file provided' }, { status: 400 })
    }
    
    console.log('Processing file:', file.name, 'Type:', file.type, 'Size:', file.size)
    
    let content = ''
    let extractionMethod = 'unknown'
    
    if (file.type === 'application/pdf' || file.name.toLowerCase().endsWith('.pdf')) {
      // For PDFs, try methods in order of reliability
      const extractionMethods = [
        { name: 'jina-ai', fn: extractPDFTextWithJina },
        { name: 'gemini-vision', fn: extractPDFWithGeminiVision },
        { name: 'pdf-js', fn: extractPDFTextWithPDFJS }
      ]
      
      let lastError = null
      
      for (const method of extractionMethods) {
        try {
          console.log(`Trying ${method.name} extraction...`)
          content = await method.fn(file)
          extractionMethod = method.name
          
          // Validate the extracted content
          if (isValidTextContent(content)) {
            console.log(`‚úÖ ${method.name} succeeded, content length:`, content.length)
            break
          } else {
            console.log(`‚ùå ${method.name} produced invalid content`)
            content = ''
          }
        } catch (error) {
          console.error(`${method.name} failed:`, error)
          lastError = error
          continue
        }
      }
      
      if (!content) {
        return NextResponse.json({ 
          error: 'Failed to extract readable text from PDF. This PDF might be:\n‚Ä¢ Image-based (scanned document)\n‚Ä¢ Password protected\n‚Ä¢ Corrupted or using unsupported encoding\n‚Ä¢ Contains only graphics/charts\n\nPlease try:\n‚Ä¢ Converting to text format first\n‚Ä¢ Using OCR software if it\'s a scanned document\n‚Ä¢ Ensuring the PDF has selectable text' 
        }, { status: 400 })
      }
      
    } else if (file.type === 'text/markdown' || file.name.toLowerCase().endsWith('.md')) {
      content = await file.text()
      extractionMethod = 'direct-text'
    } else if (file.type === 'text/plain' || file.name.toLowerCase().endsWith('.txt')) {
      content = await file.text()
      extractionMethod = 'direct-text'
    } else {
      return NextResponse.json({ 
        error: `Unsupported file type: ${file.type}. Please upload PDF, Markdown (.md), or Text (.txt) files.` 
      }, { status: 400 })
    }
    
    console.log(`Final content extracted via ${extractionMethod}:`)
    console.log('Length:', content.length)
    console.log('First 300 chars:', content.substring(0, 300))
    console.log('Last 300 chars:', content.substring(Math.max(0, content.length - 300)))
    
    // Generate AI analysis
    const analysis = await generateEnhancedFileAnalysis(content, file.name, extractionMethod)
    
    return NextResponse.json({ analysis })
  } catch (error) {
    console.error('Error analyzing file:', error)
    return NextResponse.json(
      { error: `Failed to analyze file: ${error instanceof Error ? error.message : 'Unknown error'}` },
      { status: 500 }
    )
  }
}

function isValidTextContent(text: string): boolean {
  if (!text || text.trim().length < 100) {
    return false
  }
  
  // Check for readable content ratio
  const readableChars = (text.match(/[a-zA-Z0-9\s.,!?;:'"()\-\n\r\t]/g) || []).length
  const readableRatio = readableChars / text.length
  
  if (readableRatio < 0.7) {
    console.log('‚ùå Low readable ratio:', readableRatio)
    return false
  }
  
  // Check for meaningful words (not random strings)
  const words = text.toLowerCase().split(/\s+/)
  const meaningfulWords = words.filter(word => {
    // Filter out random strings, hex codes, and garbage
    return word.length >= 3 && 
           word.length <= 20 && 
           !/^[0-9a-f]{8,}$/.test(word) && // hex codes
           !/^[a-z0-9_]{8,}$/.test(word) && // random strings
           /[aeiou]/.test(word) && // has vowels
           !/^[0-9]+$/.test(word) // not just numbers
  })
  
  const meaningfulRatio = meaningfulWords.length / Math.max(words.length, 1)
  
  if (meaningfulRatio < 0.3) {
    console.log('‚ùå Low meaningful words ratio:', meaningfulRatio)
    return false
  }
  
  // Check for common English words
  const commonWords = ['the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'this', 'that', 'these', 'those', 'a', 'an']
  const hasCommonWords = commonWords.some(word => text.toLowerCase().includes(word))
  
  if (!hasCommonWords) {
    console.log('‚ùå No common English words found')
    return false
  }
  
  console.log('‚úÖ Content validation passed:', {
    readableRatio,
    meaningfulRatio,
    hasCommonWords,
    length: text.length
  })
  
  return true
}

async function extractPDFTextWithJina(file: File): Promise<string> {
  if (!JINA_API_KEY) {
    throw new Error('Jina AI API key not configured')
  }

  const arrayBuffer = await file.arrayBuffer()
  const base64 = Buffer.from(arrayBuffer).toString('base64')
  
  const response = await fetch('https://r.jina.ai/', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${JINA_API_KEY}`
    },
    body: JSON.stringify({
      url: `data:application/pdf;base64,${base64}`,
      options: {
        parse_pdf: true,
        extract_text: true,
        return_format: 'text'
      }
    })
  })
  
  if (!response.ok) {
    throw new Error(`Jina AI API error: ${response.status}`)
  }
  
  const result = await response.json()
  const extractedText = result.data || result.text || result.content || ''
  
  if (!extractedText || extractedText.length < 100) {
    throw new Error('Insufficient text extracted via Jina AI')
  }
  
  return extractedText
}

async function extractPDFWithGeminiVision(file: File): Promise<string> {
  if (!GEMINI_API_KEY) {
    throw new Error('Gemini API key not configured')
  }

  try {
    // Convert PDF to base64
    const arrayBuffer = await file.arrayBuffer()
    const base64 = Buffer.from(arrayBuffer).toString('base64')
    
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=${GEMINI_API_KEY}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [{
            role: 'user',
            parts: [
              {
                text: 'Please extract all the readable text content from this PDF document. Return only the actual text content, no analysis or commentary. If the PDF contains tables, preserve their structure. If there are multiple pages, include all text from all pages.'
              },
              {
                inline_data: {
                  mime_type: 'application/pdf',
                  data: base64
                }
              }
            ]
          }],
          generationConfig: {
            temperature: 0.1,
            maxOutputTokens: 8000
          }
        })
      }
    )
    
    if (!response.ok) {
      throw new Error(`Gemini Vision API error: ${response.status}`)
    }
    
    const data = await response.json()
    const extractedText = data.candidates[0].content.parts[0].text
    
    if (!extractedText || extractedText.length < 100) {
      throw new Error('Insufficient text extracted via Gemini Vision')
    }
    
    return extractedText
  } catch (error) {
    console.error('Gemini Vision extraction error:', error)
    throw error
  }
}

async function extractPDFTextWithPDFJS(file: File): Promise<string> {
  try {
    // Dynamic import of PDF.js
    const pdfjsLib = await import('pdfjs-dist/legacy/build/pdf.js')
    
    // Set worker source to CDN
    pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js'
    
    const arrayBuffer = await file.arrayBuffer()
    const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise
    
    let fullText = ''
    
    // Extract text from each page
    for (let pageNum = 1; pageNum <= pdf.numPages; pageNum++) {
      const page = await pdf.getPage(pageNum)
      const textContent = await page.getTextContent()
      
      const pageText = textContent.items
        .map((item: any) => item.str)
        .join(' ')
      
      if (pageText.trim()) {
        fullText += `\n\n--- Page ${pageNum} ---\n\n${pageText}`
      }
    }
    
    if (!fullText.trim() || fullText.length < 100) {
      throw new Error('Insufficient text extracted via PDF.js')
    }
    
    return fullText.trim()
  } catch (error) {
    console.error('PDF.js extraction error:', error)
    throw error
  }
}

async function generateEnhancedFileAnalysis(content: string, filename: string, extractionMethod: string) {
  if (!GEMINI_API_KEY) {
    throw new Error('Gemini API key not configured')
  }
  
  // Analyze content characteristics
  const wordCount = content.split(/\s+/).filter(word => word.length > 0).length
  const sentences = content.split(/[.!?]+/).filter(s => s.trim().length > 10)
  const paragraphs = content.split(/\n\s*\n/).filter(p => p.trim().length > 20)
  
  // Detect content type
  const hasCode = /```|function|class|import|export|const|let|var|def|public|private|return|if\s*\(|for\s*\(|while\s*\(/.test(content)
  const hasMarkdown = /#{1,6}\s|^\*\s|\[.*\]$$.*$$|`.*`/.test(content)
  const hasTechnicalTerms = /\b(API|database|server|client|framework|library|algorithm|data|system|application|software|technology|programming|development|code|function|method|class|object|variable|parameter|return|execute|implement|configure|install|deploy|debug|test|version|update|upgrade|download|upload|interface|protocol|network|security|authentication|authorization|encryption|decryption|hash|token|session|cookie|cache|storage|memory|processor|CPU|GPU|RAM|disk|file|directory|folder|path|URL|HTTP|HTTPS|SSL|TLS|TCP|UDP|IP|DNS|domain|subdomain|port|firewall|router|switch|gateway|proxy|load balancer|container|docker|kubernetes|cloud|AWS|Azure|GCP|Linux|Windows|macOS|Ubuntu|CentOS|shell|terminal|command|script|batch|PowerShell|bash|zsh|git|github|gitlab|bitbucket|repository|commit|branch|merge|pull request|issue|bug|feature|release|deployment|CI\/CD|DevOps|agile|scrum|kanban|project management|documentation|README|license|open source|proprietary|commercial|enterprise|startup|business|marketing|sales|customer|user|client|stakeholder|requirement|specification|design|architecture|pattern|model|schema|entity|relationship|query|SQL|NoSQL|MongoDB|PostgreSQL|MySQL|SQLite|Redis|Elasticsearch|JSON|XML|YAML|CSV|REST|GraphQL|SOAP|microservice|monolith|scalability|performance|optimization|monitoring|logging|analytics|metrics|dashboard|report|visualization|chart|graph|table|list|array|object|string|number|boolean|null|undefined|true|false)\b/gi.test(content)
  
  // Extract meaningful topics (improved)
  const meaningfulWords = content.toLowerCase()
    .split(/\s+/)
    .filter(word => {
      const cleanWord = word.replace(/[^\w]/g, '')
      return cleanWord.length >= 4 && 
             cleanWord.length <= 20 &&
             !/^[0-9]+$/.test(cleanWord) &&
             !/^[0-9a-f]{8,}$/.test(cleanWord) &&
             /[aeiou]/.test(cleanWord) &&
             !['this', 'that', 'these', 'those', 'with', 'from', 'they', 'them', 'their', 'there', 'where', 'when', 'what', 'which', 'will', 'would', 'could', 'should', 'might', 'must', 'shall', 'can\'t', 'won\'t', 'don\'t', 'didn\'t', 'isn\'t', 'aren\'t', 'wasn\'t', 'weren\'t', 'haven\'t', 'hasn\'t', 'hadn\'t'].includes(cleanWord)
    })
  
  const wordFreq = new Map<string, number>()
  meaningfulWords.forEach(word => {
    const cleanWord = word.replace(/[^\w]/g, '')
    wordFreq.set(cleanWord, (wordFreq.get(cleanWord) || 0) + 1)
  })
  
  const topTopics = Array.from(wordFreq.entries())
    .sort((a, b) => b[1] - a[1])
    .slice(0, 8)
    .map(([word]) => word)
    .filter(word => word.length > 3)
  
  // Truncate content for analysis
  const maxContentLength = 8000
  const truncatedContent = content.length > maxContentLength 
    ? content.substring(0, maxContentLength) + '\n\n[Content truncated for analysis...]'
    : content
  
  const prompt = `
Analyze this document content and provide detailed insights. This is real extracted text from a ${filename} file.

Document Statistics:
- Word Count: ${wordCount}
- Sentences: ${sentences.length}
- Paragraphs: ${paragraphs.length}
- Contains Code: ${hasCode}
- Contains Markdown: ${hasMarkdown}
- Technical Content: ${hasTechnicalTerms}
- Top Topics: ${topTopics.join(', ')}
- Extraction Method: ${extractionMethod}

ACTUAL DOCUMENT CONTENT:
${truncatedContent}

Based on the ACTUAL content above, provide a comprehensive analysis in JSON format:

{
  "summary": "Write a detailed 4-5 sentence summary of what this specific document is actually about, based on the real content you can see above. Be specific about the topics, purpose, and scope.",
  "features": [
    "List 5 specific features or aspects of this document based on actual content",
    "Include specific topics, concepts, or sections you can identify",
    "Mention any notable structure, formatting, or organization",
    "Reference actual content elements you observe",
    "Note any special characteristics of this particular document"
  ],
  "technologies": [
    "List actual technologies, tools, frameworks, or systems mentioned in the content",
    "Include programming languages, platforms, or software referenced",
    "Add methodologies, standards, or protocols discussed",
    "Only include items actually present in the text"
  ],
  "useCases": [
    "Identify 3 specific real-world applications based on the document's actual content and purpose",
    "Consider who would use this document and for what specific purposes",
    "Base recommendations on the actual topics and information provided"
  ],
  "insights": "Provide detailed insights about this specific document including: its primary purpose, target audience, complexity level, key concepts covered, practical value, and how it could be used. Reference specific content elements you observed. Be detailed and specific to this particular document."
}

IMPORTANT: Base your entire analysis on the actual content provided above. Do not provide generic responses. Reference specific topics, concepts, and information you can see in the document content.
`

  try {
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key=${GEMINI_API_KEY}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [{ role: 'user', parts: [{ text: prompt }] }],
          generationConfig: {
            temperature: 0.2,
            maxOutputTokens: 2500,
            topP: 0.8,
            topK: 40
          }
        })
      }
    )
    
    if (!response.ok) {
      throw new Error(`Gemini API error: ${response.status}`)
    }
    
    const data = await response.json()
    const text = data.candidates[0].content.parts[0].text
    
    try {
      const jsonMatch = text.match(/\{[\s\S]*\}/)
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0])
        
        // Validate the response quality
        if (parsed.summary && parsed.summary.length > 100 &&
            parsed.features && parsed.features.length >= 3 &&
            parsed.useCases && parsed.useCases.length >= 2 &&
            parsed.insights && parsed.insights.length > 100) {
          return parsed
        }
      }
    } catch (parseError) {
      console.error('Failed to parse AI response as JSON:', parseError)
    }
    
    // High-quality fallback based on actual content analysis
    return {
      summary: `This document contains ${wordCount} words across ${sentences.length} sentences and ${paragraphs.length} paragraphs. The content focuses on ${topTopics.slice(0, 3).join(', ')} and appears to be ${hasTechnicalTerms ? 'technical documentation or educational material' : 'informational content'}. ${hasCode ? 'It includes code examples and technical implementations, suggesting it\'s meant for developers or technical professionals.' : 'The content is primarily explanatory and conceptual in nature.'} The document was successfully extracted using ${extractionMethod} and provides comprehensive coverage of its subject matter.`,
      features: [
        `Comprehensive content with ${wordCount} words organized in ${paragraphs.length} main sections`,
        `Primary topics include: ${topTopics.slice(0, 4).join(', ')}`,
        hasCode ? 'Contains code examples, functions, and technical implementations' : 'Focuses on conceptual explanations and theoretical content',
        `Document structure: ${sentences.length} sentences across multiple sections`,
        `Successfully extracted using ${extractionMethod} with high content quality`
      ],
      technologies: hasTechnicalTerms ? topTopics.slice(0, 6) : ['Document Processing', 'Text Analysis', 'Content Management'],
      useCases: [
        `Reference material for professionals working with ${topTopics[0] || 'the documented subject matter'}`,
        `Educational resource for learning about ${topTopics[1] || 'the covered topics'}`,
        `${hasCode ? 'Technical documentation for developers and engineers' : 'Knowledge base for research and information purposes'}`
      ],
      insights: `This document provides substantial content about ${topTopics.slice(0, 3).join(', ')} with ${wordCount} words of detailed information. The material is well-structured with ${paragraphs.length} main sections and appears to target ${hasTechnicalTerms ? 'technical professionals, developers, or engineers' : 'general audiences interested in the subject matter'}. ${hasCode ? 'The inclusion of code examples and technical implementations makes it particularly valuable for hands-on learning and practical application.' : 'The explanatory nature of the content makes it suitable for educational and reference purposes.'} The successful extraction using ${extractionMethod} ensures high content fidelity, making this document valuable for knowledge sharing, training, and reference purposes.`
    }
  } catch (apiError) {
    console.error('Gemini API error:', apiError)
    throw new Error('Failed to generate AI analysis')
  }
}

```
